---
title: "ActualData"
author: "Richard Arnold"
date: '2024-01-26'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
load("opar.Rda")
library(readxl)
library(dplyr)
library(tidyverse)
library(tidyr)
library(readxl)
library(ggplot2)
library(maps)
library(sf)
library(geojsonsf)
library(rmapshaper)

library(algae)
source("funcs.R")
source("maps.R")
```

Subsets of Tasman/Marlborough

```{r}
bbox.tasmar <- c(1570,5370,1725,5520)*1000
xlim.tasmar <- bbox.tasmar[c(1,3)]
ylim.tasmar <- bbox.tasmar[c(2,4)]

bbox.marlselect <- c(1645,5415,1720,5495)*1000
bbox.marlselect <- c(1645,5412,1725,5502)*1000
xlim.marlselect <- bbox.marlselect[c(1,3)]
ylim.marlselect <- bbox.marlselect[c(2,4)]
xlim.havelock <- c(1660,1675)*1000
ylim.havelock <- c(5425,5440)*1000
xlim.nydia <- c(1662,1677)*1000
ylim.nydia <- c(5437,5450)*1000
xlim.arapawa <- c(1695,1718)*1000
ylim.arapawa <- c(5432,5452)*1000

# Coastal polygons for mapping
bbox.marlselect.polygon <- st_polygon(list(cbind(bbox.marlselect[c(1,3,3,1,1)],
                                                 bbox.marlselect[c(2,2,4,4,2)])))
coast.marlselect <- st_crop(coast, bbox.marlselect.polygon)

bbox.tasmar.polygon <- st_polygon(list(cbind(bbox.tasmar[c(1,3,3,1,1)],
                                             bbox.tasmar[c(2,2,4,4,2)])))
coast.tasmar <- st_crop(coast, bbox.tasmar.polygon)

# polygons in model
habspoly_sf <- geojson_sf("data/HABS_exp_6_release_polygons.geojson")
habspoly_sf <- st_transform(habspoly_sf, crs=st_crs(coast))
marlpoly_sf <- geojson_sf("data/Entire_marlb_polygons_volume.geojson")
marlpoly_sf <- st_transform(marlpoly_sf, crs=st_crs(coast))

marlpoly_sf.trim <- ms_erase(marlpoly_sf, coast.marlselect) 

globalcrs <- 4326
marlcrs <- st_crs(marlpoly_sf.trim)
```

Migration matrices

```{r}
getmatrices <- TRUE
getmatrices <- FALSE
if(getmatrices) {
  # Connection and migration matrices for the polygons
  fname <- "data/connectivity_matrix.xlsx"
  nsheets <- length(excel_sheets(fname))
  conn <- lapply(1:nsheets, function(i) read_excel(fname, sheet=i, col_names=FALSE))
  names(conn) <- excel_sheets(fname)

  #fname <- "data/Migration_matrices_04_to_07_2018.xls"
  fname <- "data/migration_matrix.xlsx"
  nsheets <- length(excel_sheets(fname))
  migr <- lapply(1:nsheets, function(i) read_excel(fname, sheet=i, col_names=FALSE))
  names(migr) <- excel_sheets(fname)
  matdates <- as.Date(names(migr),format="%Y%m%d")
}
```

Plot examples

```{r}
plot(st_geometry(coast.marlselect), col="darkgreen", reset=FALSE, xlim=xlim.havelock, ylim=ylim.havelock,
     main="Original polygons")
plot(st_geometry(marlpoly_sf), col="yellow", add=TRUE)
plot(st_centroid(st_geometry(marlpoly_sf)), pch="+", col="red", add=TRUE)
```

```{r}
plot(st_geometry(coast.marlselect), col="darkgreen", reset=FALSE, xlim=xlim.havelock, ylim=ylim.havelock,
     main="Trimmed polygons")
plot(st_geometry(marlpoly_sf.trim), col="yellow", add=TRUE)
plot(st_centroid(st_geometry(marlpoly_sf.trim)), pch="+", col="red", add=TRUE)
```

Full region

```{r}
plot(st_geometry(coast.marlselect), col="darkgreen", reset=FALSE,
     main="Trimmed polygons")
plot(st_geometry(marlpoly_sf.trim), col="yellow", add=TRUE)
plot(st_centroid(st_geometry(marlpoly_sf.trim)), pch="+", col="red", add=TRUE)
```

Volumes by colour

```{r}
plot((marlpoly_sf.trim %>% mutate(vol=volume/1e9))["vol"], key.pos=4, reset=FALSE, 
     main="Polygon volumes and centroids")#, xlim=xlim.havelock, ylim=ylim.havelock)
plot(st_geometry(coast.marlselect), col="darkgreen", add=TRUE)
plot(st_centroid(st_geometry(marlpoly_sf.trim)), pch="+", col="white", add=TRUE)
```

```{r}
plot((marlpoly_sf.trim %>% mutate(depth=volume/st_area(marlpoly_sf.trim)))["depth"], key.pos=4, reset=FALSE, 
     main="Polygon mean depths and centroids")#, xlim=xlim.havelock, ylim=ylim.havelock)
plot(st_geometry(coast.marlselect), col="darkgreen", add=TRUE)
plot(st_centroid(st_geometry(marlpoly_sf.trim)), pch="+", col="white", add=TRUE)
```


From Romain:

The full dataset is named “All MSQP phyto data to 01.05.23”. 
Coordinates for the sampling sites are located in the “Raw_MSQP_Locations”.

Questions for Romain:

1. there are 306 locations -- all are GNNNA or PGNNNA (NNN=three numeric digits)(A=letter A-Q) 
   [we only want the PG and G ones]

1. location PG121 (Onepipi) has no coordinates (lon=0, lat=0) should be as follows?
          lon       lat       x       y
     174.3733 -41.13811 1715253 5445003

   from Romain: -41.138812 174.368901

1. 86 of the locations have the same NNN designation, just with P or PG, and the same location
   Of the others with the same NNN most seem to be the close in location and name, 
   but a few (PG121  Onepipi and G121 Nydia) are long way apart.
   Which locations do we actual want to use?  Should we only use SITETYPE="PHYTO" (i.e. remove
   "ESTAR" - and there are two with no SITETYPE: G114, G119 - I guess these should be "ESTAR"?)
   
   use all of them
   
1. 11 of the locations are not in any of the ocean polygons - some fall outside of the polygon
   tiling (e.g. Durville), but others are on land but close to the sea
   
   they are likely just outside
   
1. In the detection data, which REPORTED_NAME values should we use?  
  e.g. All beginnning with "Alexandrium" or just "Alexandriam catanella" and "Alexandrium pacificum"?
  it'd be good to understand how to filter this data set as a whole - this might need a zoom call perhaps
  
  
* use data for 2018 and later
* we should only use Alexandrium pacificum - (catanella should be replaced pacificum, but there shouldn't
  be any catanella from 2018 onwards) [don't use Alexandrium SPP]
* sites are available online
  https://mpi.maps.arcgis.com/apps/webappviewer/index.html?id=fbdacfcb945c46118ff105ee45142fbe

```{r}
list.files("data/confidential")
```

Locations

Note: corrected locations as follows in the file "Raw_MSQP_Locations-Corrected.csv"

 - PG121 - Onepipi - did not have lon/lat: corrected to same lon/lat as PG092 Onepipi
 - G062 - D'Urville - fully outside tiled region - no match: OK leave as non-matching - no change to coordinates
 - G086 - Head Nikau - close to shore - OK retain: match to closest polygon
 - G096 - Te Mahia - on land - and a long way in: clearly wrong!  On MPI map Te Mahia should be at x=1681390.0056, y=5436803.2623
          But label on MPI map is G108?  
          in our list though G108 is Port Hardy (which is on D'Urville Island...)
          However MPI list of Port Hardy is G108 too, so the MPI map label is wrong too.
          Need to fix these coordinates to x=1681390.0056, y=5436803.2623 lon=173.9709, lat=-41.21606
 - G105 - Black Rock - OK - this is at the head of an inlet - OK retain: match to closest polygon
 - G128 - Cook Strait 1 - too far out: remove
 - PG017 - Anakoha Bay - OK - at the end of an inlet - OK retain: match to G017 (174.095 -41.004 1692086 5460222)
 - PG062 - D'Urville - fully outside tiled region - no match: remove
 - PG086 - Head Nikau - close to shore - OK retain: match to closest polygon
 - PG111 - Kenepuru Head - inland: should be the same as G111 (1693614 5441549), and not as recorded (1689756 5448481)
           Need to fix these coordinates: match to G111 Kenepuru Head
 - PG128 - Robertson Point - to far out to sea - no match: remove
 - PG237 - Port Gore 3 - on land - clearly wrong - should be (1700423.1103 5454097.5219)
           Need to fix these coordinates - match to G237 (1705190 5453050)

Use all of these

```{r}
fname <- paste0("data/confidential/","Raw_MSQP_Locations-Corrected.csv")
habloc <- read.csv(fname)
# convert locations to sf object
habloc_sf <- st_as_sf(habloc %>% mutate(xp=x,yp=y), 
                      coords=c("xp","yp"),
                      crs=marlcrs,
                      agr="constant")
# identify which polygon each location falls into
habloc_sf <- habloc_sf %>% 
  mutate(intersection=as.integer(st_intersects(geometry, marlpoly_sf)),
         CLUSTER_ID=if_else(is.na(intersection),NA,marlpoly_sf$CLUSTER_ID[intersection])) %>%
  select(-intersection)
```

Also get locations from the MPI website - but these are confusing, so we won't use them

```{r}
fnamempi1 <- paste0("data/confidential/","Marine_biotoxin_sample_site_locations_-_View.csv")
fnamempi2 <- paste0("data/confidential/","Non-Commercial_Regular_Sites_for_the_Shellfish_Biotoxin_-_View.csv")
mpiloc1 <- read.csv(fnamempi1)
mpiloc2 <- read.csv(fnamempi2)
names(mpiloc1)[1:2] <- c("lon","lat")
any(mpiloc1$code %in% habloc$siteID) # yes
any(mpiloc2$code %in% habloc$siteID) # none
all(habloc$siteID %in% mpiloc1$code) # no
is.unique(mpiloc1$code) # FALSE
mpiloc1.u <- do.call(rbind, by(mpiloc1, mpiloc1$code, function(x) x[1,,drop=FALSE]))
is.unique(mpiloc1.u$code) # TRUE
habloc_sf <- merge(habloc_sf, mpiloc1.u, by.x="siteID", by.y="code", all.x=TRUE, suffix=c("",".mpi"))
nrow(habloc_sf) # 306

habloc <- habloc_sf %>% st_drop_geometry()
```

```{r}
habloc$dd <- sqrt((habloc$lon-habloc$lon.mpi)^2 + (habloc$lat-habloc$lat.mpi)^2)
hist(habloc$dd, breaks=50)
habloc[!is.na(habloc$dd) & habloc$dd>0.1,]
```


```{r}
#View(habloc)
nrow(habloc) # 306
View(habloc)

#is.unique(habloc$siteID) # TRUE
#table(habloc$SITETYPE,exclude=NULL) # "", "ESTAR" and "PHYTO"
#      ESTAR PHYTO 
#    2   198   106 
#table(habloc$SITETYPE, substring(habloc$siteID,1,1), exclude=NULL)
#          G   P
#          2   0
#  ESTAR 197   1
#  PHYTO   0 106

# are the P and G sites the same?
hp <- habloc%>%filter(substring(siteID,1,1)=="P")  
hg <- habloc%>%filter(substring(siteID,1,1)=="G")
hp$siteNumber <- substring(hp$siteID,3)
hg$siteNumber <- substring(hg$siteID,2)
is.unique(hp$siteNumber) # TRUE
is.unique(hg$siteNumber) # TRUE
hpg <- merge(hp,hg,all=TRUE,by="siteNumber",suffixes=c(".p",".g"))
hpg$dx <- hpg$x.p-hpg$x.g
hpg$dy <- hpg$y.p-hpg$y.g
hpg[1:2,]
idx <- !is.na(hpg$x.p) & !is.na(hpg$x.g)
nrow(hpg[idx,]) # 103
# many differences are zero
table(hpg[idx,]$lon.p-hpg[idx,]$lon.g) # 87 are zero out of 103
table(hpg[idx,]$lat.p-hpg[idx,]$lat.g) # 88 are zero out of 103
table(hpg$dx) # 86 are zero out of 103
table(hpg$dy) # 86 are zero out of 103
hpg$matched <- FALSE
hpg$matched[idx] <- hpg$dx[idx]==0 & hpg$dy[idx]==0
table(hpg$matched) # FALSE=117, TRUE=86
table(hpg$matched[idx]) # FALSE=17, TRUE=86
View(hpg[idx & !hpg$matched,])
# particular bad match is PG121 (Onepipi) and G121 (Nydia Bay Mouth)

range(habloc$lon) # min is zero
habloc[habloc$lon==0,] # Location PG121 has lon=0, lat=0: Onepipi
## lon=174.37325650  lat=-41.13810965
#onepipi <- data.frame(lon=174.37325650, lat=-41.13810965)
## lon=174.368901, lat=-41.138812
#onepipi <- data.frame(lon=174.368901, lat=-41.138812)
#onepipi.lonlat <- st_as_sf(onepipi,
#                           coords=c("lon","lat"),
#                           crs=globalcrs,
#                           agr="constant")
#onepipi.xy <- st_transform(onepipi.lonlat, marlcrs)
#xy <- unclass(onepipi.xy$geometry[[1]])
#onepipi$x <- xy[1]; onepipi$y <- xy[2]
#onepipi
#x=1714893.2113, y=5444907.4273
#ra_getxy(onepipi.xy) #1714886 5444930
```

```{r}
plot(coast.tasmar$geometry, col="dark green", reset=FALSE, xlim=xlim.tasmar, ylim=ylim.tasmar)
rect(xlim.tasmar[1], ylim.tasmar[1], xlim.tasmar[2], ylim.tasmar[2])
plot(st_geometry(habloc_sf), pch=16, col="red", add=TRUE)
#points(habloc$x, habloc$y, pch=16, col="red")
title("Collection points in Tasman/Malborough")
```

```{r}
plot(coast.marlselect$geometry, col="dark green", xlim=xlim.marlselect, ylim=ylim.marlselect)
rect(xlim.marlselect[1], ylim.marlselect[1], xlim.marlselect[2], ylim.marlselect[2])
plot(st_geometry(habloc_sf), pch=16, col="red", add=TRUE)
#points(habloc$x, habloc$y, pch=16, col="red")
title("Collection points in Malborough")
```

Plot collection points within polygons

```{r}
siteid <- "G009"
cid <- habloc_sf$CLUSTER_ID[habloc_sf$siteID==siteid]
plot(st_geometry(coast.marlselect), reset=FALSE, xlim=xlim.nydia, ylim=ylim.nydia, col="darkgreen",
     main=habloc_sf$site_name[habloc_sf$siteID==siteid])
plot(st_geometry(marlpoly_sf.trim %>% filter(CLUSTER_ID==cid)), col="yellow", add=TRUE)
plot(st_geometry(habloc_sf %>% filter(siteID==siteid)), pch=16, col="red", cex=1, add=TRUE)
axis(1); axis(2); box()
```

Which points are not matched to a polygon?

```{r}
plot(coast.marlselect$geometry, col="dark green", xlim=xlim.marlselect, ylim=ylim.marlselect)
rect(xlim.marlselect[1], ylim.marlselect[1], xlim.marlselect[2], ylim.marlselect[2])
plot(st_geometry(habloc_sf %>% filter(is.na(CLUSTER_ID))), pch=16, col="red", add=TRUE)
#points(habloc$x, habloc$y, pch=16, col="red")
title("Collection points in Malborough\nnot matched to an ocean polygon")
```

```{r}
idx <- sapply(st_within(habloc_sf, bbox.marlselect.polygon),length)==1
#View(habloc_sf %>% filter(is.na(CLUSTER_ID) & idx)) #%>% as.data.frame()
outofarea_sf <- habloc_sf %>% filter(is.na(CLUSTER_ID) & idx) 

# Find the closest polygon
closest <- list()
for(i in seq_len(nrow(outofarea_sf))){
    closest[[i]] <- marlpoly_sf.trim[which.min(st_distance(marlpoly_sf.trim, outofarea_sf[i,])),]
}
outofarea_sf$CLUSTER_ID_closest <- sapply(closest, function(x) x$CLUSTER_ID)
outofarea <- outofarea_sf %>% st_drop_geometry()

outofarea_sf
## 7 sites, 2 are repeats
```

Simple feature collection with 7 features and 17 fields
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: 1659699 ymin: 5416581 xmax: 1708427 ymax: 5469771
Projected CRS: NZGD2000 / New Zealand Transverse Mercator 2000
  siteID   X       site_name SITETYPE     lon     lat       x       y notes CLUSTER_ID  lon.mpi  lat.mpi F__OBJECTID  id
1   G062  76        Durville    ESTAR 173.709 -40.921 1659699 5469771               NA       NA       NA          NA  NA
2   G086 100      Head Nikau    ESTAR 173.896 -41.170 1675161 5441984               NA 173.8956 -41.1701         165  76
3   G105 119      Black Rock    ESTAR 174.047 -41.114 1687903 5448060               NA       NA       NA          NA  NA
4   G128 142   Cook Strait 1    ESTAR 174.297 -41.395 1708427 5416581               NA 174.2967 -41.3953         636 856
5  PG062  43        Durville    PHYTO 173.709 -40.921 1659699 5469771               NA       NA       NA          NA  NA
6  PG086  53      Head Nikau    PHYTO 173.896 -41.170 1675161 5441984               NA       NA       NA          NA  NA
7  PG128  76 Robertson Point    PHYTO 174.297 -41.395 1708427 5416581               NA       NA       NA          NA  NA
  sample_type          name                geometry CLUSTER_ID_closest
1        <NA>          <NA> POINT (1659699 5469771)                227
2          PP    Head Nikau POINT (1675161 5441984)                403
3        <NA>          <NA> POINT (1687903 5448060)                 46
4          SF Cook Strait 1 POINT (1708427 5416581)                334
5        <NA>          <NA> POINT (1659699 5469771)                227
6        <NA>          <NA> POINT (1675161 5441984)                403
7        <NA>          <NA> POINT (1708427 5416581)                334

```{r}
for(i in seq_len(nrow(outofarea_sf))) {
  sid <- outofarea_sf$siteID[i]
  sname <- outofarea_sf$site_name[i]
  cid <- outofarea_sf$CLUSTER_ID_closest[i]
  idx <- habloc$siteID==sid
  xy <- c(habloc$x[idx], habloc$y[idx])
  plot(st_geometry(coast.marlselect), reset=FALSE, col="darkgreen",
       xlim=xy[1]+c(-1,1)*8000,
       ylim=xy[2]+c(-1,1)*8000,
       main=paste0("Site ", sid, " Polygon ",cid, " (",sname,")"))
  plot(st_geometry(marlpoly_sf.trim %>% filter(CLUSTER_ID==cid)), col="yellow", add=TRUE)
  plot(st_geometry(outofarea_sf %>% filter(siteID==sid)), pch=16, col="red", cex=1, add=TRUE)
  axis(1); axis(2); box()
}
```

 - G062 - D'Urville - fully outside tiled region - no match: remove
 - G086 - Head Nikau - close to shore - OK retain
 - G105 - Black Rock - OK - this is at the head of an inlet - OK retain
 - G128 - Cook Strait 1 - too far out: remove
 - PG062 - D'Urville - fully outside tiled region - no match: remove
 - PG086 - Head Nikau - close to shore - OK retain
 - PG128 - Robertson Point - to far out to sea - no match: remove

```{r}
outofarea_retain_sf <- outofarea_sf %>% filter(siteID%in%c("G086","G105","PG086"))
outofarea_retain_sf
```


```{r}
plot(st_geometry(coast.marlselect), reset=FALSE, col="darkgreen",
     main="Matching out of area sites to nearest polygon")
plot(st_geometry(marlpoly_sf.trim %>% filter(CLUSTER_ID%in%outofarea_retain_sf$CLUSTER_ID_closest)), col="yellow", add=TRUE)
plot(st_geometry(outofarea_retain_sf), pch=16, col="red", cex=1, add=TRUE)
axis(1); axis(2); box()
```

```{r}
habloc_sf <- merge(habloc_sf, st_drop_geometry(outofarea_retain_sf)[,c("siteID","CLUSTER_ID_closest")], all.x=TRUE)
idx <- is.na(habloc_sf$CLUSTER_ID) & !is.na(habloc_sf$CLUSTER_ID_closest)
habloc_sf$CLUSTER_ID[idx] <- habloc_sf$CLUSTER_ID_closest[idx]
habloc_sf$CLUSTER_ID_closest <- NULL
habloc <- habloc_sf %>% st_drop_geometry()
#write.csv(habloc, file="data/habloc.csv", row.names=FALSE)
```

```{r}
habloc <- read.csv("data/habloc.csv")
habloc_sf <- st_as_sf(habloc %>% mutate(xp=x,yp=y), 
                      coords=c("xp","yp"),
                      crs=marlcrs,
                      agr="constant")
```

Detections

```{r, error=FALSE, message=FALSE, warning=FALSE}
fname <- paste0("data/confidential/","All MSQP phyto data to 01.05.23.xlsx")
habdat <- read_excel(fname) %>% as.data.frame()
#View(habdat)
nrow(habdat) # 292786
habdat <- habdat[habdat$Site_Code%in%habloc$siteID,]
nrow(habdat) # 101842
habdat[1:2,]
```

Assign each event to a polygon

```{r}
habdat <- merge(habdat, habloc[,c("siteID","site_name","CLUSTER_ID","x","y")], by.x="Site_Code", by.y="siteID", all.x=TRUE)
nrow(habdat) # 101842
habdat <- habdat[!is.na(habdat$CLUSTER_ID),]
nrow(habdat) # 88479
table(habdat$REPORTED_NAME)
alexnames <- c("Alexandrium spp.",
               "Alexandrium cf. pacificum","Alexandrium pacificum",
               "Alexandrium cf. catenella","Alexandrium catenella")
habdat.alex <- habdat[habdat$REPORTED_NAME%in%alexnames,]
nrow(habdat.alex) # 887
#table(habdat.alex$REPORTED_NAME)
```

    Alexandrium catenella Alexandrium cf. catenella Alexandrium cf. pacificum     Alexandrium pacificum          Alexandrium spp. 
                      260                         9                        32                       576                        10 

```{r}
events <- habdat %>% group_by(Site_Code,SITE_DESCRIPTION,SAMPLED_DATE) %>% summarise(ndetections=n()) %>% ungroup()
nrow(events) # 12824
table(events$ndetections)
events[1:10,]
```

```{r}
events.alex <- merge(events, 
                     habdat.alex[,c("Site_Code","SITE_DESCRIPTION","SAMPLED_DATE","REPORTED_NAME",
                                    "Data_Value","UNITS","x","y","site_name","CLUSTER_ID")],
                     by=c("Site_Code","SITE_DESCRIPTION","SAMPLED_DATE"),
                     all.x=TRUE)
nrow(events.alex) # 12830: more than 12824
```

Check that the site names match
```{r}
check <- habdat.alex %>% group_by(Site_Code,SITE_DESCRIPTION,site_name) %>% summarise(nrow=n()) %>% ungroup()
check$SITE_DESCRIPTION <- gsub(".Marine$","",check$SITE_DESCRIPTION)
all(tolower(check$SITE_DESCRIPTION)==tolower(check$site_name)) # TRUE: same data source
#nrow(check) # 119
#View(check) # yes they do match
```


```{r}
tt <- table(paste(habdat.alex$Site_Code,habdat.alex$SAMPLED_DATE))
nn <- names(tt[tt>1])
habdat.alex[paste(habdat.alex$Site_Code,habdat.alex$SAMPLED_DATE)%in%nn,]
events.alex[paste(events.alex$Site_Code,events.alex$SAMPLED_DATE)%in%nn,]
```
 G010 2019-02-26 14:00:00  G073 2019-02-26 15:30:00 PG091 2014-02-26 13:53:00 
                        2                         2                         5 

     Site_Code         SITE_DESCRIPTION        SAMPLED_DATE ndetections             REPORTED_NAME   Data_Value      UNITS       x       y
272        G010       Hallam Cove.Marine 2019-02-26 14:00:00          13 Alexandrium cf. pacificum         2700 CELL_LITRE 1669388 5461359
273        G010       Hallam Cove.Marine 2019-02-26 14:00:00          13          Alexandrium spp.          400 CELL_LITRE 1669388 5461359
4927       G073 Head Of Nydia Bay.Marine 2019-02-26 15:30:00           9     Alexandrium pacificum         4000 CELL_LITRE 1665852 5442296
4928       G073 Head Of Nydia Bay.Marine 2019-02-26 15:30:00           9          Alexandrium spp.          200 CELL_LITRE 1665852 5442296
12504     PG091                Tio Point 2014-02-26 13:53:00          17     Alexandrium catenella         1300 CELL_LITRE 1704754 5434402
12505     PG091                Tio Point 2014-02-26 13:53:00          17     Alexandrium catenella         2100 CELL_LITRE 1704754 5434402
12506     PG091                Tio Point 2014-02-26 13:53:00          17     Alexandrium catenella         1400 CELL_LITRE 1704754 5434402
12507     PG091                Tio Point 2014-02-26 13:53:00          17     Alexandrium catenella          300 CELL_LITRE 1704754 5434402
12508     PG091                Tio Point 2014-02-26 13:53:00          17     Alexandrium catenella Not Detected CELL_LITRE 1704754 5434402

2014 detections will be ignorable (use data from 2018 only)
G010 and G073 remove Alexandrium spp. cases.
Achieve this by taking the events with the maximum Data_Value

```{r}
idx <- paste(events.alex$Site_Code,events.alex$SAMPLED_DATE)%in%nn
events.alex[idx,]
d1 <- events.alex[idx,]
d0 <- events.alex[!idx,]

d1 <- d1 %>% 
  group_by(Site_Code) %>%
  filter(Data_Value==max(as.numeric(Data_Value),na.rm=TRUE)) %>%
  ungroup() 
d1

events.alex <- rbind(d0,d1)
nrow(events.alex) # 12824 - OK
table(events.alex$Data_Value)
events.alex$Value <- as.numeric(events.alex$Data_Value)
events.alex$Value[is.na(events.alex$Value)] <- 0
events.alex$site_name <- NULL; events.alex$x <- NULL; events.alex$y <- NULL; events.alex$CLUSTER_ID <- NULL
events.alex$SITE_DESCRIPTION <- NULL
events.alex$UNITS <- NULL
events.alex <- merge(events.alex, habloc_sf[,c("siteID","site_name","x","y","CLUSTER_ID")] %>% st_drop_geometry(), 
                     by.x="Site_Code", by.y="siteID", all.x=TRUE)
#table(events.alex$ndetections,exclude=NULL)
events.alex$REPORTED_NAME[is.na(events.alex$REPORTED_NAME)] <- "No detection"
table(events.alex$REPORTED_NAME,exclude=NULL)
events.alex$Date <- as.Date(substring(events.alex$SAMPLED_DATE,1,10), format="%Y-%m-%d")
events.alex$DateTime <- as.POSIXct(events.alex$SAMPLED_DATE)

# Convert dates to weeks: move the date back to the previous Monday
events.alex$mDate <- make.monday(events.alex$Date)
events.alex$mWeek <- as.integer(events.alex$mDate+3)%/%7
events.alex$mDay <- as.numeric(format(events.alex$Date,"%u"))

#data.frame(format(events.alex$Date,"%Y-%m-%d, %a"), 
#          format(events.alex$mDate,"%Y-%m-%d, %a"),
#           events.alex$mWeek,
#           events.alex$mDay)[1:10,]

table(format(events.alex$Date, "%a"))
table(format(events.alex$mDate, "%a"))
#gsub("-.$","-1",format(events.alex$Date, "%Y-%m-%u")[1:20])
#gsub("-.$","w1",format(events.alex$Date, "%Y-%m-%u")[1:20])
```

```{r}
#write.csv(events.alex %>% st_drop_geometry(),file="data/eventsAlexandrium.csv",row.names=FALSE)
events.alex <- read.csv("data/eventsAlexandrium.csv")
events.alex$Date <- as.Date(events.alex$Date)
events.alex$mDate <- as.Date(events.alex$mDate)
events.alex$DateTime <- as.POSIXct(events.alex$SAMPLED_DATE)
nrow(events.alex)
View(events.alex)
```

Check for multiple events in the same week
```{r}
tt <- table(paste(events.alex$Site_Code,events.alex$mWeek))
table(tt[tt>1])
```

This happens a lot!

  2   5   6 
215   2   3 

Make a unique version - just take the first sample in each week
```{r}
events.alex.week1 <- events.alex %>%
                      group_by(Site_Code,mWeek) %>%
                      filter(mDay==min(mDay)) %>%
                      ungroup()
#View(events.alex.week1)
is.unique(paste(events.alex$Site_Code, events.alex$mWeek)) # FALSE
is.unique(paste(events.alex.week1$Site_Code, events.alex.week1$mWeek)) # FALSE

tt <- table(paste(events.alex.week1$Site_Code,events.alex.week1$mWeek))
table(tt[tt>1])
```

A few cases of multiple samples on a single day

 2  5  6 
10  2  3 

```{r}
nn <- names(tt[tt>1])
events.alex.week1[paste(events.alex.week1$Site_Code,events.alex.week1$mWeek) %in% nn,]
```

```{r}
events.alex.week <- events.alex %>%
                      group_by(Site_Code,mWeek) %>%
                      filter(DateTime==min(DateTime)) %>%
                      ungroup()
#View(events.alex.week)
is.unique(paste(events.alex$Site_Code, events.alex$mWeek)) # FALSE
is.unique(paste(events.alex.week$Site_Code, events.alex.week$mWeek)) # TRUE
nrow(events.alex.week) # 12586
```

```{r}
#write.csv(events.alex.week %>% st_drop_geometry(),file="data/eventsAlexandriumWeek.csv",row.names=FALSE)
events.alex.week <- read.csv("data/eventsAlexandriumWeek.csv")
events.alex.week$Date <- as.Date(events.alex.week$Date)
events.alex.week$mDate <- as.Date(events.alex.week$mDate)
events.alex.week$DateTime <- as.POSIXct(events.alex.week$SAMPLED_DATE)
nrow(events.alex.week)
#View(events.alex.week)
```

```{r}
hist(events.alex$Date, breaks="years")
```

```{r}
diff(range(events.alex.week$mWeek)) # 573 weeks
range(events.alex.week$Date)  #"2012-04-30" "2023-04-26"
nrow(events.alex.week) # 12586
nrow(events.alex.week[events.alex.week$Date>=as.Date("2018-01-01"),]) # 6411
```

```{r}
plot(events.alex.week$Date, events.alex.week$Value, 
     xlab="Date", ylab="Cells/litre",
     main="Detections of Alexandrium")
```

Find the largest intensity observation in each polygon over the entire period
```{r}
maxobs <- events.alex.week %>% 
  filter(Date>=as.Date("2018-01-01")) %>%
  group_by(CLUSTER_ID) %>% 
  summarise(Value1000=max(Value)/1000) %>%
  ungroup()
maxobs_sf <- merge(marlpoly_sf.trim, maxobs, all.x=TRUE)
```


```{r}
plot(maxobs_sf["Value1000"], key.pos=4, reset=FALSE, 
     main="Maximum Alexandrium detections")
mtext("1-Jan-2018 to 26-Apr-2023", side=1, line=-0.5, cex=0.5, adj=1)#, xlim=xlim.havelock, ylim=ylim.havelock)
plot(st_geometry(coast.marlselect), col="darkgreen", add=TRUE)
plot(st_centroid(st_geometry(marlpoly_sf.trim)), pch="+", col="white", add=TRUE)
```

```{r}
wmin <- min(events.alex.week$mWeek[events.alex.week$Date>=as.Date("2018-01-01")])
wmax <- max(events.alex.week$mWeek)
c(wmin,wmax) # 2505-2782 (278 weeks)
```

```{r}
for(w in wmin+(0:10)) {
  thisweek.poly <- merge(marlpoly_sf.trim, 
             events.alex.week[events.alex.week$mWeek==w,c("CLUSTER_ID","Value")] %>% mutate(Value1000=Value/1000)) 
  plot(thisweek.poly %>% st_geometry(), 
       key.pos=4,
       main=paste0("Week ",w), 
       reset=FALSE)
  plot(st_geometry(coast.marlselect), col="darkgreen", add=TRUE)
  plot(st_centroid(st_geometry(marlpoly_sf.trim)), pch="+", col="white", add=TRUE)
}
```



```{r}
for(w in wmin+(0:10)) {
  plot(merge(marlpoly_sf.trim, 
             events.alex.week[events.alex.week$mWeek==w,c("CLUSTER_ID","Value")] %>% mutate(Value1000=Value/1000)) %>% 
         st_geometry(), 
       breaks=c(25*(0:7)), 
       key.pos=4,
       main=paste0("Week ",w), 
       reset=FALSE)
  plot(st_geometry(coast.marlselect), col="darkgreen", add=TRUE)
  plot(st_centroid(st_geometry(marlpoly_sf.trim)), pch="+", col="white", add=TRUE)
}
```


